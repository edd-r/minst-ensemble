import os
import sys

import numpy as np
import pandas as pd
import kneed as kn


import sklearn.decomposition as decomp

# add project modules to the path
path_to_module = os.path.abspath(os.path.join(os.getcwd(), "..", "src/"))
sys.path.append(path_to_module)

import src.models.train_model as train_model

file_names = {"X_train": "X_train.npy",
              "X_test": "X_test.npy",
              "y_train": "y_train.npy",
              "y_test": "y_test.npy"
              }

def find_pca_knee(pca,
                  sensitivity=10,
                  ):

    df = pd.DataFrame({"explained_variance": pca.explained_variance_,
                       "explained_variance_ratio": pca.explained_variance_ratio_,
                       "components": [n for n in range(len(pca.explained_variance_))]}
                      )
    df["explained_variance_ratio"] = df["explained_variance_ratio"].cumsum()

    var_kneedle = kn.knee_locator.KneeLocator(x=df["components"],
                                              y=df["explained_variance"],
                                              S=sensitivity,
                                              curve="convex",
                                              direction="decreasing"
                                              )

    explained_var_kneedle = kn.knee_locator.KneeLocator(x=df["components"],
                                                        y=df["explained_variance_ratio"],
                                                        S=sensitivity,
                                                        curve="concave",
                                                        direction="increasing"
                                                        )

    return var_kneedle, explained_var_kneedle


def combine_train_test_data(file_path=os.path.join(os.getcwd(), "data/processed/"),
                            file_names=file_names,
                            augmented_suffix="_augmented",
                            blurred_suffix="_blurred",
                            scaled_suffix="_scaled"
                            ):

    data_dict = train_model.load_processed_data(file_path,
                                                file_names,
                                                augmented_suffix,
                                                blurred_suffix,
                                                scaled_suffix
                                                )

    # combine X and y data
    X = np.concatenate([data_dict["X_train"], data_dict["X_test"]])
    y = np.concatenate([data_dict["y_train"], data_dict["y_test"]])

    return X, y


def main(data_model=decomp.PCA()):

    X,y combine_train_test_data()

    data_model.fit(X)
    var_knee, explained_var_knee = find_pca_knee(pca=data_model)

    X_decomp_explaine_var = data_model.components_

def dimensionality_reduce_data(x_data_model= decomp.pca):

    var_knee, explained_var_knee = find_pca_knee(pca)

    return var_knee.knee, explained_var_knee.knee


